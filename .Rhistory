show_progress = show_progress)
}
if(occ.based) {
eoos <- do.call(rbind.data.frame, result[[n.levels]][grepl("EOO", names(result[[n.levels]]))])
dimnames(eoos) <- list(sp_names[[n.levels]], "EOO")
shps <- result[[n.levels]][grepl("spatial.polygon", names(result[[n.levels]]))]
for (i in 1:length(shps))
slot(slot(shps[[i]], "polygons")[[1]], "ID") <- sp_names[[n.levels]][!is.na(eoos$EOO)][i]
shps <- do.call(rbind, shps)
shps_df <- SpatialPolygonsDataFrame(shps, data.frame(tax = names(shps), row.names = names(shps)))
shps_df$tax <- as.character(shps_df$tax)
result[[n.levels]] <- eoos
rm(eoos, shps)
}
for (i in 1:length(result))
result[[i]]$n.occs <- as.double(table(XY.list[[i]]$tax))
Results_short <- merge(result[[1]], result[[2]], by="row.names",
all = TRUE, suffixes = c(".conf1",".conf2"))
if(n.levels > 2) {
for(i in 3:n.levels)
Results_short <- merge(Results_short, result[[i]],
all = TRUE, by.x="Row.names", by.y="row.names", suffixes = c("", paste0(".conf",i)))
}
names(Results_short) <- c("Species", paste0(rep(c("EOO.level.","Occs.level."),n.levels), rep(1:n.levels, each = 2)))
result1 <- Results_short[, grepl("EOO", names(Results_short))]
result1 <- do.call(rbind.data.frame,
lapply(1:nrow(result1),
function(x) round((result1[x, 1:(n.levels-1)] - result1[x, n.levels]) /
result1[x, n.levels], 5)))
names(result1) <- paste0("EOO.increase.", 1:(n.levels-1))
Results_short <- cbind.data.frame(Results_short,
result1, stringsAsFactors = FALSE)
Results_short <- Results_short[,c(1, grep("Occs", names(Results_short)),
grep("EOO.level", names(Results_short)),
grep("EOO.increase", names(Results_short)))]
if(occ.based) {
cat("Starting the occurrence-based analysis...", sep= "\n")
cat(Sys.time())
list_data <- split(XY.list[[1]], f = XY.list[[1]]$tax)
if (parallel) {
cl <- snow::makeSOCKcluster(NbeCores)
doSNOW::registerDoSNOW(cl)
message('Parallel running with ',
NbeCores, ' cores')
`%d%` <- foreach::`%dopar%`
} else {
`%d%` <- foreach::`%do%`
}
if(show_progress) {
pb <-
utils::txtProgressBar(min = 0,
max = length(list_data),
style = 3)
progress <- function(n)
utils::setTxtProgressBar(pb, n)
opts <- list(progress = progress)
} else {
opts <- NULL
}
x <- NULL
output <-
foreach::foreach(
x = 1:length(list_data),
.combine = 'c',
.options.snow = opts
) %d% {
#source("./over.valid.poly.R")
if (!parallel & show_progress)
utils::setTxtProgressBar(pb, x)
res <- .over.valid.poly(shps_df, list_data[[x]],
proj_user = proj_user, value = value)
res
}
if(parallel) snow::stopCluster(cl)
if(show_progress) close(pb)
XY.list[[1]]$prop.dist.eoo <- output
Results_long <- dplyr::left_join(XY,
XY.list[[1]][, c("recordID", "classes","prop.dist.eoo")],
by = "recordID")
Results_long$prop.dist.eoo[is.na(Results_long$prop.dist.eoo) &
Results_long$classes >= max(Results_long$classes, na.rm = TRUE)] <- 0
Results_long <- Results_long[order(Results_long$recordID), ]
Results_long <-
Results_long[, -which(names(Results_long) %in% c("recordID", "classes"))]
}
if (write_results)
utils::write.csv(Results_short, paste(getwd(), "/", file.name, ".csv", sep = ""))
if (occ.based) {
output <- list(Results_short,
Results_long)
names(output) = c("EOO.change", "Occ.influence")
} else {
output <- Results_short
}
cat("Returning the results.", sep= "\n")
output
}
EOO.sensitivity(mydf, levels.order = c(FALSE, TRUE))
EOO.sensitivity(mydf, levels.order = c(FALSE, TRUE), proj_user = 5641)
EOO.sensitivity <- function(XY,
levels.order = NULL,
occ.based = TRUE,
value = "dist",
proj_user = NULL,
exclude.area = FALSE,
country_map = NULL,
alpha = 1,
buff.alpha = 0.1,
method.range = "convex.hull",
#Name_Sp = "species1",
buff_width = 0.1,
method.less.than3 = "not comp",
write_results = FALSE,
file.name = "EOO.sensitivity.results",
parallel = FALSE,
NbeCores = 2,
show_progress = FALSE
){
XY$recordID = 1:dim(XY)[1]
if (any(is.na(XY[, c(1:2)]))) {
print(paste(
"Skipping",
length(which(rowMeans(is.na(
XY[, 1:2]
)) > 0)) ,
"occurrences because of missing coordinates for",
# if(verbose)
paste(as.character(unique(XY[which(rowMeans(is.na(XY[, 1:2])) >
0), 3])), collapse = " AND ")
))
XY1 <- XY[which(!is.na(XY[, 1])), ]
XY1 <- XY1[which(!is.na(XY1[, 2])), ]
XY1 <- as.data.frame(XY1)
} else {
XY1 <- as.data.frame(XY)
}
if (exclude.area & is.null(country_map))
stop("exclude.area is TRUE but no country_map is provided")
if (buff_width > 80)
stop("buff_width has an unrealistic value")
if (any(XY1[, 2] > 180) ||
any(XY1[, 2] < -180) ||
any(XY1[, 1] < -180) ||
any(XY1[, 1] > 180))
stop("coordinates are outside of the expected range")
if(length(unique(XY1[,4])) <2)
stop("there is only one class of confidence level")
if(!is.null(country_map))
country_map <- suppressWarnings(rgeos::gBuffer(country_map, byid=TRUE, width=0))
if (method.range == "convex.hull") {
convex.hull = TRUE
alpha.hull = FALSE
}
if (method.range == "alpha.hull") {
convex.hull = FALSE
alpha.hull = TRUE
}
if (ncol(XY1) > 4) {
colnames(XY1)[1:4] <- c("ddlat", "ddlon", "tax", "valid")
XY1$valid <- as.character(XY1$valid)
XY1$tax <- as.character(XY1$tax)
XY1 <- XY1[, c("ddlat", "ddlon", "tax", "valid", "recordID")]
} else{
colnames(XY1)[1:3] <- c("ddlat", "ddlon", "valid")
XY1$valid <- as.character(XY1$valid)
XY1$tax <- "Species 1"
XY1 <- XY1[, c("ddlat", "ddlon", "tax", "valid", "recordID")]
}
levels.order <- levels.order[levels.order %in% unique(XY1$valid)]
XY1 <- XY1[XY1$valid %in% levels.order, ]
n.levels <- length(levels.order)
if(occ.based) {
export_shp = c(rep(FALSE, n.levels - 1), TRUE)
} else {
export_shp = c(rep(FALSE, n.levels - 1), FALSE)
}
## Obtaining the data for each class of confidence level
XY1$classes <- as.double(factor(XY1$valid, levels = levels.order, labels = 1:n.levels))
XY.list <- sp_names <- vector("list", n.levels)
for(i in 1:n.levels) {
tmp <- XY1[XY1$classes >= i, ]
XY.list[[i]] <- tmp
sp_names[[i]] <- sort(unique(tmp$tax))
rm(tmp)
}
names(XY.list) <- names(sp_names) <- paste0("level.", 1:n.levels)
## Obtaining EOO for each taxon and class of confidence level
result <- vector("list", n.levels)
names(result) <- paste0("level.", 1:n.levels)
cat("Starting the EOO analysis for each species and confidence levels...", sep= "\n")
for(i in 1:length(result)) {
result[[i]] <- EOO.computing(XY = XY.list[[i]],
exclude.area = exclude.area,
buff_width = buff_width,
country_map = country_map,
write_shp = FALSE,
#Name_Sp = names_list[[i]],
method.range = method.range,
alpha = alpha,
buff.alpha = buff.alpha,
method.less.than3 = method.less.than3,
write_results = write_results,
export_shp = export_shp[i],
parallel = parallel,
NbeCores = NbeCores,
show_progress = show_progress)
}
if(occ.based) {
eoos <- do.call(rbind.data.frame, result[[n.levels]][grepl("EOO", names(result[[n.levels]]))])
dimnames(eoos) <- list(sp_names[[n.levels]], "EOO")
shps <- result[[n.levels]][grepl("spatial.polygon", names(result[[n.levels]]))]
for (i in 1:length(shps))
slot(slot(shps[[i]], "polygons")[[1]], "ID") <- sp_names[[n.levels]][!is.na(eoos$EOO)][i]
shps <- do.call(rbind, shps)
shps_df <- SpatialPolygonsDataFrame(shps, data.frame(tax = names(shps), row.names = names(shps)))
shps_df$tax <- as.character(shps_df$tax)
result[[n.levels]] <- eoos
rm(eoos, shps)
}
for (i in 1:length(result))
result[[i]]$n.occs <- as.double(table(XY.list[[i]]$tax))
Results_short <- merge(result[[1]], result[[2]], by="row.names",
all = TRUE, suffixes = c(".conf1",".conf2"))
if(n.levels > 2) {
for(i in 3:n.levels)
Results_short <- merge(Results_short, result[[i]],
all = TRUE, by.x="Row.names", by.y="row.names", suffixes = c("", paste0(".conf",i)))
}
names(Results_short) <- c("Species", paste0(rep(c("EOO.level.","Occs.level."),n.levels), rep(1:n.levels, each = 2)))
result1 <- Results_short[, grepl("EOO", names(Results_short))]
result1 <- do.call(rbind.data.frame,
lapply(1:nrow(result1),
function(x) round((result1[x, 1:(n.levels-1)] - result1[x, n.levels]) /
result1[x, n.levels], 5)))
names(result1) <- paste0("EOO.increase.", 1:(n.levels-1))
Results_short <- cbind.data.frame(Results_short,
result1, stringsAsFactors = FALSE)
Results_short <- Results_short[,c(1, grep("Occs", names(Results_short)),
grep("EOO.level", names(Results_short)),
grep("EOO.increase", names(Results_short)))]
if(occ.based) {
cat("Starting the occurrence-based analysis...", sep= "\n")
list_data <- split(XY.list[[1]], f = XY.list[[1]]$tax)
if (parallel) {
cl <- snow::makeSOCKcluster(NbeCores)
doSNOW::registerDoSNOW(cl)
message('Parallel running with ',
NbeCores, ' cores')
`%d%` <- foreach::`%dopar%`
} else {
`%d%` <- foreach::`%do%`
}
if(show_progress) {
pb <-
utils::txtProgressBar(min = 0,
max = length(list_data),
style = 3)
progress <- function(n)
utils::setTxtProgressBar(pb, n)
opts <- list(progress = progress)
} else {
opts <- NULL
}
x <- NULL
output <-
foreach::foreach(
x = 1:length(list_data),
.combine = 'c',
.options.snow = opts
) %d% {
#source("./over.valid.poly.R")
if (!parallel & show_progress)
utils::setTxtProgressBar(pb, x)
res <- .over.valid.poly(shps_df, list_data[[x]],
proj_user = proj_user, value = value)
res
}
if(parallel) snow::stopCluster(cl)
if(show_progress) close(pb)
XY.list[[1]]$prop.dist.eoo <- output
Results_long <- dplyr::left_join(XY,
XY.list[[1]][, c("recordID", "classes","prop.dist.eoo")],
by = "recordID")
Results_long$prop.dist.eoo[is.na(Results_long$prop.dist.eoo) &
Results_long$classes >= max(Results_long$classes, na.rm = TRUE)] <- 0
Results_long <- Results_long[order(Results_long$recordID), ]
Results_long <-
Results_long[, -which(names(Results_long) %in% c("recordID", "classes"))]
}
if (write_results)
utils::write.csv(Results_short, paste(getwd(), "/", file.name, ".csv", sep = ""))
if (occ.based) {
output <- list(Results_short,
Results_long)
names(output) = c("EOO.change", "Occ.influence")
} else {
output <- Results_short
}
cat("Returning the results.", sep= "\n")
output
}
EOO.sensitivity(mydf, levels.order = c(FALSE, TRUE), proj_user = 5641)
EOO.sensitivity <- function(XY,
levels.order = NULL,
occ.based = TRUE,
value = "dist",
proj_user = NULL,
exclude.area = FALSE,
country_map = NULL,
alpha = 1,
buff.alpha = 0.1,
method.range = "convex.hull",
#Name_Sp = "species1",
buff_width = 0.1,
method.less.than3 = "not comp",
write_results = FALSE,
file.name = "EOO.sensitivity.results",
parallel = FALSE,
NbeCores = 2,
show_progress = TRUE
){
XY$recordID = 1:dim(XY)[1]
if (any(is.na(XY[, c(1:2)]))) {
print(paste(
"Skipping",
length(which(rowMeans(is.na(
XY[, 1:2]
)) > 0)) ,
"occurrences because of missing coordinates for",
# if(verbose)
paste(as.character(unique(XY[which(rowMeans(is.na(XY[, 1:2])) >
0), 3])), collapse = " AND ")
))
XY1 <- XY[which(!is.na(XY[, 1])), ]
XY1 <- XY1[which(!is.na(XY1[, 2])), ]
XY1 <- as.data.frame(XY1)
} else {
XY1 <- as.data.frame(XY)
}
if (exclude.area & is.null(country_map))
stop("exclude.area is TRUE but no country_map is provided")
if (buff_width > 80)
stop("buff_width has an unrealistic value")
if (any(XY1[, 2] > 180) ||
any(XY1[, 2] < -180) ||
any(XY1[, 1] < -180) ||
any(XY1[, 1] > 180))
stop("coordinates are outside of the expected range")
if(length(unique(XY1[,4])) <2)
stop("there is only one class of confidence level")
if(!is.null(country_map))
country_map <- suppressWarnings(rgeos::gBuffer(country_map, byid=TRUE, width=0))
if (method.range == "convex.hull") {
convex.hull = TRUE
alpha.hull = FALSE
}
if (method.range == "alpha.hull") {
convex.hull = FALSE
alpha.hull = TRUE
}
if (ncol(XY1) > 4) {
colnames(XY1)[1:4] <- c("ddlat", "ddlon", "tax", "valid")
XY1$valid <- as.character(XY1$valid)
XY1$tax <- as.character(XY1$tax)
XY1 <- XY1[, c("ddlat", "ddlon", "tax", "valid", "recordID")]
} else{
colnames(XY1)[1:3] <- c("ddlat", "ddlon", "valid")
XY1$valid <- as.character(XY1$valid)
XY1$tax <- "Species 1"
XY1 <- XY1[, c("ddlat", "ddlon", "tax", "valid", "recordID")]
}
levels.order <- levels.order[levels.order %in% unique(XY1$valid)]
XY1 <- XY1[XY1$valid %in% levels.order, ]
n.levels <- length(levels.order)
if(occ.based) {
export_shp = c(rep(FALSE, n.levels - 1), TRUE)
} else {
export_shp = c(rep(FALSE, n.levels - 1), FALSE)
}
## Obtaining the data for each class of confidence level
XY1$classes <- as.double(factor(XY1$valid, levels = levels.order, labels = 1:n.levels))
XY.list <- sp_names <- vector("list", n.levels)
for(i in 1:n.levels) {
tmp <- XY1[XY1$classes >= i, ]
XY.list[[i]] <- tmp
sp_names[[i]] <- sort(unique(tmp$tax))
rm(tmp)
}
names(XY.list) <- names(sp_names) <- paste0("level.", 1:n.levels)
## Obtaining EOO for each taxon and class of confidence level
result <- vector("list", n.levels)
names(result) <- paste0("level.", 1:n.levels)
cat("Starting the EOO analysis for each species and confidence levels...", sep= "\n")
for(i in 1:length(result)) {
result[[i]] <- EOO.computing(XY = XY.list[[i]],
exclude.area = exclude.area,
buff_width = buff_width,
country_map = country_map,
write_shp = FALSE,
#Name_Sp = names_list[[i]],
method.range = method.range,
alpha = alpha,
buff.alpha = buff.alpha,
method.less.than3 = method.less.than3,
write_results = write_results,
export_shp = export_shp[i],
parallel = parallel,
NbeCores = NbeCores,
show_progress = show_progress)
}
if(occ.based) {
eoos <- do.call(rbind.data.frame, result[[n.levels]][grepl("EOO", names(result[[n.levels]]))])
dimnames(eoos) <- list(sp_names[[n.levels]], "EOO")
shps <- result[[n.levels]][grepl("spatial.polygon", names(result[[n.levels]]))]
for (i in 1:length(shps))
slot(slot(shps[[i]], "polygons")[[1]], "ID") <- sp_names[[n.levels]][!is.na(eoos$EOO)][i]
shps <- do.call(rbind, shps)
shps_df <- SpatialPolygonsDataFrame(shps, data.frame(tax = names(shps), row.names = names(shps)))
shps_df$tax <- as.character(shps_df$tax)
result[[n.levels]] <- eoos
rm(eoos, shps)
}
for (i in 1:length(result))
result[[i]]$n.occs <- as.double(table(XY.list[[i]]$tax))
Results_short <- merge(result[[1]], result[[2]], by="row.names",
all = TRUE, suffixes = c(".conf1",".conf2"))
if(n.levels > 2) {
for(i in 3:n.levels)
Results_short <- merge(Results_short, result[[i]],
all = TRUE, by.x="Row.names", by.y="row.names", suffixes = c("", paste0(".conf",i)))
}
names(Results_short) <- c("Species", paste0(rep(c("EOO.level.","Occs.level."),n.levels), rep(1:n.levels, each = 2)))
result1 <- Results_short[, grepl("EOO", names(Results_short))]
result1 <- do.call(rbind.data.frame,
lapply(1:nrow(result1),
function(x) round((result1[x, 1:(n.levels-1)] - result1[x, n.levels]) /
result1[x, n.levels], 5)))
names(result1) <- paste0("EOO.increase.", 1:(n.levels-1))
Results_short <- cbind.data.frame(Results_short,
result1, stringsAsFactors = FALSE)
Results_short <- Results_short[,c(1, grep("Occs", names(Results_short)),
grep("EOO.level", names(Results_short)),
grep("EOO.increase", names(Results_short)))]
if(occ.based) {
cat("Starting the occurrence-based analysis...", sep= "\n")
list_data <- split(XY.list[[1]], f = XY.list[[1]]$tax)
if (parallel) {
cl <- snow::makeSOCKcluster(NbeCores)
doSNOW::registerDoSNOW(cl)
message('Parallel running with ',
NbeCores, ' cores')
`%d%` <- foreach::`%dopar%`
} else {
`%d%` <- foreach::`%do%`
}
if(show_progress) {
pb <-
utils::txtProgressBar(min = 0,
max = length(list_data),
style = 3)
progress <- function(n)
utils::setTxtProgressBar(pb, n)
opts <- list(progress = progress)
} else {
opts <- NULL
}
x <- NULL
output <-
foreach::foreach(
x = 1:length(list_data),
.combine = 'c',
.options.snow = opts
) %d% {
#source("./over.valid.poly.R")
if (!parallel & show_progress)
utils::setTxtProgressBar(pb, x)
res <- .over.valid.poly(shps_df, list_data[[x]],
proj_user = proj_user, value = value)
res
}
if(parallel) snow::stopCluster(cl)
if(show_progress) close(pb)
XY.list[[1]]$prop.dist.eoo <- output
Results_long <- dplyr::left_join(XY,
XY.list[[1]][, c("recordID", "classes","prop.dist.eoo")],
by = "recordID")
Results_long$prop.dist.eoo[is.na(Results_long$prop.dist.eoo) &
Results_long$classes >= max(Results_long$classes, na.rm = TRUE)] <- 0
Results_long <- Results_long[order(Results_long$recordID), ]
Results_long <-
Results_long[, -which(names(Results_long) %in% c("recordID", "classes"))]
}
if (write_results)
utils::write.csv(Results_short, paste(getwd(), "/", file.name, ".csv", sep = ""))
if (occ.based) {
output <- list(Results_short,
Results_long)
names(output) = c("EOO.change", "Occ.influence")
} else {
output <- Results_short
}
cat("Returning the results.", sep= "\n")
output
}
EOO.sensitivity(mydf, levels.order = c(FALSE, TRUE),
proj_user = 5641)
library(ConR)
devtools::document()
devtools::document()
library(ConR)
devtools::document()
devtools::install_github("r-lib/roxygen2")
